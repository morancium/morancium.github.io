<!DOCTYPE html>
<html lang="en" data-theme="light">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Open-Sourced RAG - Ashish Singh</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@600&display=swap" rel="stylesheet">
    <style>
        .blog-post {
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }
        .blog-post img {
            max-width: 100%;
            border-radius: 8px;
            margin: 2rem 0;
        }
        .blog-post h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
        }
        .blog-post .meta {
            display: flex;
            gap: 1rem;
            margin-bottom: 2rem;
            color: var(--text-secondary);
            align-items: center;
        }
        .blog-post .content {
            line-height: 1.8;
        }
        .blog-post .content h2 {
            margin: 2rem 0 1rem;
            color: var(--accent-primary);
        }
        .blog-post .content p {
            margin-bottom: 1.5rem;
        }
        .blog-post .content ul {
            margin-bottom: 1.5rem;
            padding-left: 2rem;
        }
        .blog-post .content li {
            margin-bottom: 0.5rem;
        }
        .blog-post .content code {
            background: var(--bg-secondary);
            padding: 0.2rem 0.4rem;
            border-radius: 4px;
            font-family: monospace;
        }
        .back-to-blog {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            margin-top: 2rem;
            color: var(--accent-primary);
            text-decoration: none;
        }
        .back-to-blog:hover {
            color: var(--accent-secondary);
        }
        .github-link {
            color: var(--text-primary);
            text-decoration: none;
            font-size: 1.2rem;
            transition: color 0.3s ease;
        }
        .github-link:hover {
            color: var(--accent-primary);
        }
        .logo-link {
            text-decoration: none;
            color: inherit;
        }
        .logo-link:hover {
            opacity: 0.8;
        }
        /* Add code block styling */
        pre {
            background: var(--bg-secondary);
            padding: 1rem;
            border-radius: 8px;
            white-space: pre-wrap;
            word-wrap: break-word;
            margin: 1.5rem 0;
            font-family: monospace;
            line-height: 1.5;
        }
        pre code {
            background: none;
            padding: 0;
            font-size: 1rem;
            line-height: 1.5;
            display: block;
        }
        @media (max-width: 768px) {
            pre {
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <nav class="container">
            <a href="index.html" class="logo-link">
                <div class="logo">AS</div>
            </a>
            <button class="menu-toggle" id="menu-toggle"><i class="fas fa-bars"></i></button>
            <ul>
                <li><a href="index.html#work">Work</a></li>
                <li><a href="index.html#about">About</a></li>
                <li><a href="blog.html">Blog</a></li>
            </ul>
            <button id="theme-toggle"><i class="fas fa-moon"></i></button>
        </nav>
    </header>

    <main>
        <article class="blog-post">
            <h1>Open-Sourced RAG Pipeline: Revolutionizing Document Processing with Retrieval-Augmented Generation</h1>
            <div class="meta">
                <span><i class="far fa-calendar"></i> May 4, 2025</span>
                <span><i class="far fa-folder"></i> AI & NLP</span>
                <a href="https://github.com/morancium/open-sourced-RAG" class="github-link" target="_blank"><i class="fab fa-github"></i></a>
            </div>
            
            <div class="content">
                <img src="assest/rag-thumbnail.png" alt="Open-Sourced RAG Pipeline">
                
                <h2>Introduction</h2>
                <p>In the rapidly evolving landscape of Natural Language Processing (NLP), Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing language models' capabilities. This article introduces an open-sourced RAG pipeline, a comprehensive solution designed to transform document processing workflows across various industries.</p>

                <h2>What is RAG?</h2>
                <p>Retrieval-Augmented Generation combines the power of large language models with external knowledge retrieval. Unlike traditional language models that rely solely on their pre-trained knowledge, RAG systems can access and incorporate up-to-date information from external sources, making them more accurate and contextually aware.</p>

                <h2>Understanding the RAG Pipeline</h2>
                <p>The RAG pipeline consists of several key processes that work together to provide accurate and contextually relevant responses:</p>

                <h3>1. Document Processing and Chunking</h3>
                <p>Chunking is the process of breaking down large documents into smaller, manageable pieces while preserving their semantic meaning. The pipeline implements several strategies:</p>
                <ul>
                    <li><strong>Semantic Chunking:</strong> Text is split based on semantic boundaries (paragraphs, sections) rather than fixed character counts</li>
                    <li><strong>Overlap Strategy:</strong> Context is maintained by allowing chunks to overlap slightly, preventing information loss at boundaries</li>
                    <li><strong>Smart Chunking:</strong> LangChain's text splitters are used to maintain document structure and relationships</li>
                </ul>

                <h3>2. Vector Embedding and Storage</h3>
                <p>Once documents are chunked, they are converted into vector embeddings:</p>
                <ul>
                    <li><strong>Embedding Generation:</strong> State-of-the-art embedding models convert text into high-dimensional vectors</li>
                    <li><strong>Vector Storage:</strong> These embeddings are stored in ChromaDB with metadata for efficient retrieval</li>
                    <li><strong>Upserting:</strong> A combination of "update" and "insert" operations that:
                        <ul>
                            <li>Update existing vectors if the document has changed</li>
                            <li>Insert new vectors for new content</li>
                            <li>Maintain document versioning and history</li>
                        </ul>
                    </li>
                </ul>

                <h3>3. Retrieval Process</h3>
                <p>The retrieval process is optimized for both speed and relevance:</p>
                <ul>
                    <li><strong>Query Processing:</strong>
                        <ul>
                            <li>User queries are converted into vector embeddings</li>
                            <li>Query expansion techniques are applied for better context understanding</li>
                            <li>Complex queries with multiple components are handled</li>
                        </ul>
                    </li>
                    <li><strong>Similarity Search:</strong>
                        <ul>
                            <li>Cosine similarity is used to find the most relevant document chunks</li>
                            <li>Approximate nearest neighbor (ANN) search is implemented for efficiency</li>
                            <li>Filtering is applied based on metadata and document types</li>
                        </ul>
                    </li>
                    <li><strong>Re-ranking:</strong>
                        <ul>
                            <li>Retrieved chunks are re-ranked based on relevance to the query</li>
                            <li>Document freshness and importance are considered</li>
                            <li>Diversity sampling is applied to avoid redundant information</li>
                        </ul>
                    </li>
                </ul>

                <h3>4. Generation Process</h3>
                <p>The final step combines retrieved information with language model generation:</p>
                <ul>
                    <li><strong>Context Integration:</strong>
                        <ul>
                            <li>Relevant chunks are combined into a coherent context</li>
                            <li>Proper context window limits are maintained</li>
                            <li>Multiple document sources are handled</li>
                        </ul>
                    </li>
                    <li><strong>Prompt Engineering:</strong>
                        <ul>
                            <li>The prompt is structured to include retrieved context</li>
                            <li>System messages guide model behavior</li>
                            <li>Few-shot examples are implemented for better performance</li>
                        </ul>
                    </li>
                    <li><strong>Response Generation:</strong>
                        <ul>
                            <li>The language model generates responses</li>
                            <li>Responses are grounded in retrieved information</li>
                            <li>Coherence and relevance are maintained</li>
                        </ul>
                    </li>
                </ul>

                <h2>Key Components</h2>
                <ul>
                    <li><strong>Document Processing Layer:</strong> Multiple document formats including PDFs, images, and text files are handled</li>
                    <li><strong>Vector Storage System:</strong> ChromaDB is used for efficient vector storage and retrieval</li>
                    <li><strong>Language Model Integration:</strong> Multiple state-of-the-art models are supported</li>
                    <li><strong>Text Processing Pipeline:</strong> LangChain powers sophisticated text handling</li>
                </ul>

                <h2>Technical Implementation</h2>
                <p>The pipeline is built using several key technologies:</p>
                <ul>
                    <li><strong>Python 3.8+</strong> as the primary programming language</li>
                    <li><strong>Transformers</strong> and <strong>AutoGPTQ</strong> for language model inference</li>
                    <li><strong>ChromaDB</strong> for vector storage and retrieval</li>
                    <li><strong>LangChain</strong> for text processing and chunking</li>
                </ul>

                <h2>Supported Models</h2>
                <p>The pipeline supports several state-of-the-art language models:</p>
                <ul>
                    <li>OpenChat 3.5</li>
                    <li>Mixtral 8x7B</li>
                    <li>Vicuna 13B v1.5 16K</li>
                    <li>Zephyr 7B Beta</li>
                </ul>

                <h2>System Architecture</h2>
                <p>The pipeline consists of three main components:</p>
                <ul>
                    <li><strong>Document Processing:</strong>
                        <ul>
                            <li>OCR capabilities for image processing</li>
                            <li>PDF text extraction and processing</li>
                            <li>Text file handling</li>
                        </ul>
                    </li>
                    <li><strong>Vector Storage:</strong>
                        <ul>
                            <li>ChromaDB integration</li>
                            <li>Cosine similarity-based retrieval</li>
                            <li>Metadata management</li>
                        </ul>
                    </li>
                    <li><strong>Model Integration:</strong>
                        <ul>
                            <li>Support for multiple model architectures</li>
                            <li>Optimized inference using AutoGPTQ</li>
                            <li>Context window management</li>
                        </ul>
                    </li>
                </ul>

                <h2>Usage Example</h2>
                <p>Here's how to use the pipeline:</p>
                <pre><code>python rag_pipeline.py -s document.pdf -q "What are the key responsibilities mentioned in this document?"</code></pre>

                <h2>Technical Requirements</h2>
                <p>The system requires:</p>
                <ul>
                    <li>Minimum 16GB RAM (32GB recommended)</li>
                    <li>CUDA-compatible GPU for model inference</li>
                    <li>Sufficient disk space for model storage</li>
                </ul>

                <h2>Future Developments</h2>
                <p>Active development is focused on several enhancements:</p>
                <ul>
                    <li>Support for additional document formats</li>
                    <li>Improved retrieval algorithms</li>
                    <li>Enhanced model fine-tuning capabilities</li>
                    <li>Better memory management for large documents</li>
                </ul>

                <h2>Conclusion</h2>
                <p>This open-sourced RAG pipeline represents a significant step forward in document processing and information retrieval. By combining state-of-the-art language models with efficient vector storage and retrieval mechanisms, it provides a powerful tool that can transform how organizations process and extract insights from their documents.</p>

                <p>Contributions to this project are welcome. Whether you're interested in improving the core functionality, adding new features, or optimizing performance, your participation is encouraged.</p>

                <a href="blog.html" class="back-to-blog">
                    <i class="fas fa-arrow-left"></i> Back to Blog
                </a>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Ashish Singh. All rights reserved.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html> 